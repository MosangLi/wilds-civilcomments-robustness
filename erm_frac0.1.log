C:\anaconda\envs\wilds_robust\lib\site-packages\outdated\__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import parse_version
usage: run_expt.py [-h] -d
                   {amazon,camelyon17,civilcomments,iwildcam,ogb-molpcba,poverty,fmow,py150,rxrx1,globalwheat,celebA,domainnet,waterbirds,yelp,bdd100k,sqf,encode}
                   --algorithm
                   {ERM,groupDRO,deepCORAL,IRM,DANN,AFN,FixMatch,PseudoLabel,NoisyStudent}
                   --root_dir ROOT_DIR [--split_scheme SPLIT_SCHEME]
                   [--dataset_kwargs [DATASET_KWARGS ...]]
                   [--download [DOWNLOAD]] [--frac FRAC] [--version VERSION]
                   [--unlabeled_split {train_unlabeled,val_unlabeled,test_unlabeled,extra_unlabeled}]
                   [--unlabeled_version UNLABELED_VERSION]
                   [--use_unlabeled_y [USE_UNLABELED_Y]]
                   [--loader_kwargs [LOADER_KWARGS ...]]
                   [--unlabeled_loader_kwargs [UNLABELED_LOADER_KWARGS ...]]
                   [--train_loader {standard,group}]
                   [--uniform_over_groups [UNIFORM_OVER_GROUPS]]
                   [--distinct_groups [DISTINCT_GROUPS]]
                   [--n_groups_per_batch N_GROUPS_PER_BATCH]
                   [--unlabeled_n_groups_per_batch UNLABELED_N_GROUPS_PER_BATCH]
                   [--batch_size BATCH_SIZE]
                   [--unlabeled_batch_size UNLABELED_BATCH_SIZE]
                   [--eval_loader {standard}]
                   [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                   [--model {resnet18_ms,resnet18,resnet34,resnet50,resnet101,wideresnet50,densenet121,bert-base-uncased,distilbert-base-uncased,gin-virtual,logistic_regression,code-gpt-py,fasterrcnn,unet-seq}]
                   [--model_kwargs [MODEL_KWARGS ...]]
                   [--noisystudent_add_dropout [NOISYSTUDENT_ADD_DROPOUT]]
                   [--noisystudent_dropout_rate NOISYSTUDENT_DROPOUT_RATE]
                   [--pretrained_model_path PRETRAINED_MODEL_PATH]
                   [--load_featurizer_only [LOAD_FEATURIZER_ONLY]]
                   [--teacher_model_path TEACHER_MODEL_PATH]
                   [--transform {bert,image_base,image_resize,image_resize_and_center_crop,poverty,rxrx1}]
                   [--additional_train_transform {randaugment,weak}]
                   [--target_resolution TARGET_RESOLUTION [TARGET_RESOLUTION ...]]
                   [--resize_scale RESIZE_SCALE]
                   [--max_token_length MAX_TOKEN_LENGTH]
                   [--randaugment_n RANDAUGMENT_N]
                   [--loss_function {cross_entropy,lm_cross_entropy,MSE,multitask_bce,fasterrcnn_criterion,cross_entropy_logits}]
                   [--loss_kwargs [LOSS_KWARGS ...]]
                   [--groupby_fields GROUPBY_FIELDS [GROUPBY_FIELDS ...]]
                   [--group_dro_step_size GROUP_DRO_STEP_SIZE]
                   [--coral_penalty_weight CORAL_PENALTY_WEIGHT]
                   [--dann_penalty_weight DANN_PENALTY_WEIGHT]
                   [--dann_classifier_lr DANN_CLASSIFIER_LR]
                   [--dann_featurizer_lr DANN_FEATURIZER_LR]
                   [--dann_discriminator_lr DANN_DISCRIMINATOR_LR]
                   [--afn_penalty_weight AFN_PENALTY_WEIGHT]
                   [--safn_delta_r SAFN_DELTA_R] [--hafn_r HAFN_R]
                   [--use_hafn [USE_HAFN]] [--irm_lambda IRM_LAMBDA]
                   [--irm_penalty_anneal_iters IRM_PENALTY_ANNEAL_ITERS]
                   [--self_training_lambda SELF_TRAINING_LAMBDA]
                   [--self_training_threshold SELF_TRAINING_THRESHOLD]
                   [--pseudolabel_T2 PSEUDOLABEL_T2]
                   [--soft_pseudolabels [SOFT_PSEUDOLABELS]]
                   [--algo_log_metric ALGO_LOG_METRIC]
                   [--process_pseudolabels_function {pseudolabel_binary_logits,pseudolabel_multiclass_logits,pseudolabel_identity,pseudolabel_detection,pseudolabel_detection_discard_empty}]
                   [--val_metric VAL_METRIC]
                   [--val_metric_decreasing [VAL_METRIC_DECREASING]]
                   [--n_epochs N_EPOCHS] [--optimizer {SGD,Adam,AdamW}]
                   [--lr LR] [--weight_decay WEIGHT_DECAY]
                   [--max_grad_norm MAX_GRAD_NORM]
                   [--optimizer_kwargs [OPTIMIZER_KWARGS ...]]
                   [--scheduler {linear_schedule_with_warmup,cosine_schedule_with_warmup,ReduceLROnPlateau,StepLR,FixMatchLR,MultiStepLR}]
                   [--scheduler_kwargs [SCHEDULER_KWARGS ...]]
                   [--scheduler_metric_split {train,val}]
                   [--scheduler_metric_name SCHEDULER_METRIC_NAME]
                   [--process_outputs_function {binary_logits_to_pred,multiclass_logits_to_pred,None}]
                   [--evaluate_all_splits [EVALUATE_ALL_SPLITS]]
                   [--eval_splits EVAL_SPLITS [EVAL_SPLITS ...]]
                   [--eval_only [EVAL_ONLY]] [--eval_epoch EVAL_EPOCH]
                   [--device DEVICE [DEVICE ...]] [--seed SEED]
                   [--log_dir LOG_DIR] [--log_every LOG_EVERY]
                   [--save_step SAVE_STEP] [--save_best [SAVE_BEST]]
                   [--save_last [SAVE_LAST]] [--save_pred [SAVE_PRED]]
                   [--no_group_logging [NO_GROUP_LOGGING]]
                   [--progress_bar [PROGRESS_BAR]] [--resume [RESUME]]
                   [--use_wandb [USE_WANDB]]
                   [--wandb_api_key_path WANDB_API_KEY_PATH]
                   [--wandb_kwargs [WANDB_KWARGS ...]]
run_expt.py: error: the following arguments are required: -d/--dataset, --algorithm, --root_dir
